{
 "cells": [
  {
   "source": [
    "![CRISP_DM](../reports/figures/CRISP_DM.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Already up to date.\n Number of regions rows: 412\n"
    }
   ],
   "source": [
    "# %load ../src/data/get_data.py\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import git\n",
    "\n",
    "# # Data Understanding\n",
    "# \n",
    "# ## Data Sources\n",
    "# * RKI, webscraping https://www.rki.de/DE/Content/InfAZ/N/Neuartiges_Coronavirus/Fallzahlen.html\n",
    "# * John Hopkins (GIT) https://github.com/CSSEGISandData/COVID-19.git\n",
    "# * Rest API to retrieve covid data from NPGEO https://npgeo-corona-npgeo-de.hub.arcgis.com/\n",
    "# \n",
    "\n",
    "# ###  John Hopkins Source\n",
    "\n",
    "def get_johns_hopkins():\n",
    "    ''' Get data by a git pull request, the source code has to be pulled first\n",
    "        Result is stored in the predifined csv structure\n",
    "    '''\n",
    "    # git_pull = subprocess.Popen( \"/usr/bin/git pull\" ,\n",
    "    #                      cwd = os.path.dirname( 'data/raw/COVID-19/' ),\n",
    "    #                      shell = True,\n",
    "    #                      stdout = subprocess.PIPE,\n",
    "    #                      stderr = subprocess.PIPE )\n",
    "    # (out, error) = git_pull.communicate()\n",
    "\n",
    "\n",
    "    # print(\"Error : \" + str(error))\n",
    "    # print(\"out : \" + str(out))\n",
    "\n",
    "    g = git.cmd.Git(\"../data/raw/COVID-19\")\n",
    "\n",
    "    msg = g.pull()\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "# ## REST API CALLS\n",
    "\n",
    "\n",
    "## data request for Germany\n",
    "\n",
    "def get_current_data_germany():\n",
    "    ''' Get current data from germany, attention API endpoint not too stable\n",
    "        Result data frame is stored as pd.DataFrame\n",
    "\n",
    "    '''\n",
    "    # 16 states\n",
    "    #data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/Coronaf%C3%A4lle_in_den_Bundesl%C3%A4ndern/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    # 400 regions / Landkreise\n",
    "    data=requests.get('https://services7.arcgis.com/mOBPykOjAyBO2ZKk/arcgis/rest/services/RKI_Landkreisdaten/FeatureServer/0/query?where=1%3D1&outFields=*&outSR=4326&f=json')\n",
    "\n",
    "    json_object=json.loads(data.content)\n",
    "    full_list=[]\n",
    "    \n",
    "    for pos,each_dict in enumerate (json_object['features'][:]):\n",
    "        full_list.append(each_dict['attributes'])\n",
    "\n",
    "    pd_full_list=pd.DataFrame(full_list)\n",
    "    pd_full_list.to_csv('../data/raw/NPGEO/GER_state_data.csv',sep=';')\n",
    "    print(' Number of regions rows: '+str(pd_full_list.shape[0]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_johns_hopkins()\n",
    "    get_current_data_germany()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Process Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of rows stored: 62776\n Number of rows stored: 62776\n Number of rows stored: 59708\nNumber of rows stored - Full Flat Table: 236\n"
    }
   ],
   "source": [
    "# %load ../src/data/Process_JohnHopkins_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def store_relational_JH_data_confirmed():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'confirmed'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "def store_relational_JH_data_deaths():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'deaths'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_deaths.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "def store_relational_JH_data_recovered():\n",
    "    ''' Transformes the COVID data in a relational data set\n",
    "\n",
    "    '''\n",
    "\n",
    "    data_path='../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "    pd_raw=pd.read_csv(data_path)\n",
    "\n",
    "    pd_data_base=pd_raw.rename(columns={'Country/Region':'country',\n",
    "                      'Province/State':'state'})\n",
    "\n",
    "    pd_data_base['state']=pd_data_base['state'].fillna('no')\n",
    "\n",
    "    pd_data_base=pd_data_base.drop(['Lat','Long'],axis=1)\n",
    "\n",
    "\n",
    "    pd_relational_model=pd_data_base.set_index(['state','country']) \\\n",
    "                                .T                              \\\n",
    "                                .stack(level=[0,1])             \\\n",
    "                                .reset_index()                  \\\n",
    "                                .rename(columns={'level_0':'date',\n",
    "                                                   0:'recovered'},\n",
    "                                                  )\n",
    "\n",
    "    pd_relational_model['date']=pd_relational_model.date.astype('datetime64[ns]')\n",
    "\n",
    "    pd_relational_model.to_csv('../data/processed/COVID_relational_recovered.csv',sep=';',index=False)\n",
    "    print(' Number of rows stored: '+str(pd_relational_model.shape[0]))\n",
    "\n",
    "\n",
    "def store_confimed_data_for_sir():\n",
    "    data_path = '../data/raw/COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "    pd_raw = pd.read_csv(data_path)\n",
    "    pd_raw = pd_raw.drop(['Lat','Long','Province/State'],axis=1)\n",
    "    pd_raw = pd_raw.rename(columns={'Country/Region':'country'})\n",
    "    pd_flat_table = pd_raw.set_index('country') \\\n",
    "                    .T \\\n",
    "                    .stack(level=[0]) \\\n",
    "                    .reset_index() \\\n",
    "                    .rename(columns={'level_0':'date',\n",
    "                                    0:'confirmed'}\n",
    "                                    )\n",
    "    pd_flat_table['date'] = pd_flat_table.date.astype('datetime64[ns]')\n",
    "    pd_flat_table = pd.pivot_table(pd_flat_table, values='confirmed', index='date', columns='country', aggfunc=np.sum, fill_value=0).reset_index()\n",
    "    pd_flat_table.to_csv('../data/processed/COVID_full_flat_table.csv',sep=';',index = False)\n",
    "    #print(pd_flat_table.tail())\n",
    "    print('Number of rows stored - Full Flat Table: '+str(pd_flat_table.shape[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    store_relational_JH_data_confirmed()\n",
    "    store_relational_JH_data_deaths()\n",
    "    store_relational_JH_data_recovered()\n",
    "    store_confimed_data_for_sir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Filter and Doubling Rate Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the test slope is: [2.]\nDone\n"
    }
   ],
   "source": [
    "# %load ../src/features/build_features.py\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "def get_doubling_time_via_regression(in_array):\n",
    "    ''' Use a linear regression to approximate the doubling rate\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        in_array : pandas.series\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        Doubling rate: double\n",
    "    '''\n",
    "\n",
    "    y = np.array(in_array)\n",
    "    #print(y)\n",
    "    X = np.arange(-1,2).reshape(-1, 1)\n",
    "    #print(X)\n",
    "\n",
    "    assert len(in_array)==3\n",
    "    reg.fit(X,y)\n",
    "    intercept=reg.intercept_\n",
    "    slope=reg.coef_\n",
    "\n",
    "\n",
    "    return intercept/slope\n",
    "\n",
    "\n",
    "def savgol_filter(df_input,column='confirmed',window=5):\n",
    "    ''' Savgol Filter which can be used in groupby apply function \n",
    "        it ensures that the data structure is kept'''\n",
    "    window=5, \n",
    "    degree=1\n",
    "    df_result=df_input\n",
    "    \n",
    "    filter_in=df_input[column].fillna(0) # attention with the neutral element here\n",
    "    \n",
    "    result=signal.savgol_filter(np.array(filter_in),\n",
    "                           5, # window size used for filtering\n",
    "                           1)\n",
    "    df_result[column+'_filtered']=result\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def rolling_reg(df_input,col='confirmed'):\n",
    "    ''' input has to be a data frame'''\n",
    "    ''' return is single series (mandatory for group by apply)'''\n",
    "    days_back=3\n",
    "    result=df_input[col].rolling(\n",
    "                window=days_back,\n",
    "                min_periods=days_back).apply(get_doubling_time_via_regression,raw=False)\n",
    "    return result\n",
    "\n",
    "def calc_filtered_data(df_input,filter_on='confirmed'):\n",
    "    '''  Calculate savgol filter and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "    df_output=df_input.copy() # we need a copy here otherwise the filter_on column will be overwritten\n",
    "\n",
    "    pd_filtered_result=df_output[['state','country',filter_on]].groupby(['state','country']).apply(savgol_filter)#.reset_index()\n",
    "\n",
    "    #print('--+++ after group by apply')\n",
    "    #print(pd_filtered_result[pd_filtered_result['country']=='Germany'].tail())\n",
    "\n",
    "    #df_output=pd.merge(df_output,pd_filtered_result[['index',str(filter_on+'_filtered')]],on=['index'],how='left')\n",
    "    df_output=pd.merge(df_output,pd_filtered_result[[str(filter_on+'_filtered')]],left_index=True,right_index=True,how='left')\n",
    "    #print(df_output[df_output['country']=='Germany'].tail())\n",
    "    return df_output.copy()\n",
    "\n",
    "def calc_doubling_rate(df_input,filter_on='confirmed'):\n",
    "    ''' Calculate approximated doubling rate and return merged data frame\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df_input: pd.DataFrame\n",
    "        filter_on: str\n",
    "            defines the used column\n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: pd.DataFrame\n",
    "            the result will be joined as a new column on the input data frame\n",
    "    '''\n",
    "\n",
    "    must_contain=set(['state','country',filter_on])\n",
    "    assert must_contain.issubset(set(df_input.columns)), ' Erro in calc_filtered_data not all columns in data frame'\n",
    "\n",
    "\n",
    "    pd_DR_result= df_input.groupby(['state','country']).apply(rolling_reg,filter_on).reset_index()\n",
    "\n",
    "    pd_DR_result=pd_DR_result.rename(columns={filter_on:filter_on+'_DR',\n",
    "                             'level_2':'index'})\n",
    "\n",
    "    #we do the merge on the index of our big table and on the index column after groupby\n",
    "    df_output=pd.merge(df_input,pd_DR_result[['index',str(filter_on+'_DR')]],left_index=True,right_on=['index'],how='left')\n",
    "    df_output=df_output.drop(columns=['index'])\n",
    "\n",
    "\n",
    "    return df_output\n",
    "\n",
    "\n",
    "def get_daily_list(total_list):\n",
    "    ''' Calculate Daily change in cases from the cummulative gathered list\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        total_list: list\n",
    "            A python list containing the cummulative cases\n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        df_output: list\n",
    "            the result will be a list containing daily change in values\n",
    "    '''\n",
    "    daily_list=[]\n",
    "    daily_list.append(total_list.pop(0))\n",
    "    for each in range(len(total_list)):\n",
    "        if each == 0:\n",
    "            daily_list.append(total_list[each] - total_list[0])\n",
    "        else:\n",
    "            daily_list.append(total_list[each] - total_list[each-1])\n",
    "    \n",
    "    return daily_list\n",
    "\n",
    "def calc_daily_values_all_countries(all_countries):\n",
    "    df_daily_all= pd.DataFrame()\n",
    "    for each_country in all_countries:\n",
    "        daily_list = get_daily_list(list(pd_daily[pd_daily['country']==each_country]['confirmed']))\n",
    "        df_daily = pd.DataFrame(np.array(daily_list))\n",
    "\n",
    "        \n",
    "        df_daily_death = np.array(get_daily_list(list(pd_daily[pd_daily['country']==each_country]['deaths'])))\n",
    "        df_daily_recov = np.array(get_daily_list(list(pd_daily_recov[pd_daily['country']==each_country]['recovered'])))\n",
    "\n",
    "\n",
    "        df_daily = df_daily.rename(columns={0:'daily_confirmed'})\n",
    "        df_daily['daily_deaths'] = df_daily_death\n",
    "        df_daily['daily_recovered'] = df_daily_recov\n",
    "        df_daily['date'] = np.array(pd_daily[pd_daily['country']==each_country]['date'])\n",
    "        df_daily['country'] = np.array(pd_daily[pd_daily['country']==each_country]['country'])\n",
    "        df_daily_all = pd.concat([df_daily_all,df_daily])\n",
    "\n",
    "    return df_daily_all\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_data_reg=np.array([2,4,6])\n",
    "    result=get_doubling_time_via_regression(test_data_reg)\n",
    "    print('the test slope is: '+str(result))\n",
    "    pd_JH_data=pd.read_csv('../data/processed/COVID_relational_confirmed.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data=pd_JH_data.sort_values('date',ascending=True).copy()\n",
    "\n",
    "    #test_structure=pd_JH_data[((pd_JH_data['country']=='US')|\n",
    "    #                  (pd_JH_data['country']=='Germany'))]\n",
    "\n",
    "    pd_result_larg=calc_filtered_data(pd_JH_data)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg)\n",
    "    pd_result_larg=calc_doubling_rate(pd_result_larg,'confirmed_filtered')\n",
    "    \n",
    "\n",
    "    mask=pd_result_larg['confirmed']>100\n",
    "    pd_result_larg['confirmed_filtered_DR']=pd_result_larg['confirmed_filtered_DR'].where(mask, other=np.NaN)\n",
    "    pd_result_larg = pd_result_larg.reset_index()\n",
    "\n",
    "    pd_JH_data_deaths=pd.read_csv('../data/processed/COVID_relational_deaths.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data_deaths=pd_JH_data_deaths.sort_values('date',ascending=True).reset_index(drop=True).copy()\n",
    "    pd_DR_result_death = pd_JH_data_deaths[['state','country','deaths']].reset_index()\n",
    "    pd_result_larg=pd.merge(pd_result_larg,pd_DR_result_death[['index','deaths']],on=['index'],how='left')\n",
    "\n",
    "    pd_result_larg.to_csv('../data/processed/COVID_final_set.csv',sep=';',index=False)\n",
    "\n",
    "    pd_JH_data_recov=pd.read_csv('../data/processed/COVID_relational_recovered.csv',sep=';',parse_dates=[0])\n",
    "    pd_JH_data_recov=pd_JH_data_recov.sort_values('date',ascending=True).reset_index(drop=True).copy()\n",
    "    pd_DR_result_recov = pd_JH_data_recov[['state','date','country','recovered']].reset_index()\n",
    "    pd_DR_result_recov.to_csv('../data/processed/COVID_final_recov_set.csv',sep=';',index=False)\n",
    "\n",
    "\n",
    "    pd_daily = pd_result_larg[['state','country','confirmed','date','deaths']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "    pd_daily_recov = pd.read_csv('../data/processed/COVID_final_recov_set.csv',sep=';',parse_dates=[0])\n",
    "    pd_daily_recov = pd_daily_recov[['state','country','recovered','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "    df_daily_all= calc_daily_values_all_countries(pd_daily['country'].unique())\n",
    "    df_daily_all = df_daily_all.reset_index()\n",
    "    df_daily_all.daily_deaths = df_daily_all.daily_deaths.mask(df_daily_all.daily_deaths.lt(0), 0)\n",
    "    df_daily_all.to_csv('../data/processed/COVID_final_daily_set.csv',sep=';',index=False)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) SIR Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SIR Modelling Started.\nNumber of rows stored - : 201\nSIR Modelling Ended.\n"
    }
   ],
   "source": [
    "# %load ../src/models/SIR.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy import integrate\n",
    "import warnings\n",
    "\n",
    "'''\n",
    "    Default paramter initializations\n",
    "'''\n",
    "N0 = 1300000000\n",
    "I0 = 200  #Infected population\n",
    "S0 = N0 - I0    #Suspected population\n",
    "R0 = 0          #Recovered population\n",
    "beta = 0.5      #Rate of infection\n",
    "gamma = 0.1     #Rate of recovery\n",
    "t = 0\n",
    "\n",
    "def Handle_SIR_Modelling(ydata):\n",
    "    global t\n",
    "    t = np.arange(len(ydata))\n",
    "\n",
    "    global I0\n",
    "    I0 = ydata[0]   #Infected population\n",
    "    popt, pcov = optimize.curve_fit(fit_odeint, t, ydata, maxfev=10000)\n",
    "    fitted = fit_odeint(t, *popt)\n",
    "    return t, ydata, fitted\n",
    "\n",
    "def SIR_model_fit(SIR, time, beta, gamma):\n",
    "    '''\n",
    "    Simple SIR model implementation.\n",
    "    S: Suspected population\n",
    "    I: Infected population\n",
    "    R: Recovered population\n",
    "    beta: rate of infection\n",
    "    gamma: rate of recovery\n",
    "    time: for integral as define in odeint function of scipy.integrate\n",
    "    as per slides: ds+dI+dR = 0 and S+R+I=N (total population)\n",
    "\n",
    "    Make a note tht in this model a recovered person can not get infected again.\n",
    "    '''\n",
    "\n",
    "    S,I,R = SIR\n",
    "    dS_dt = -beta*S*I/N0\n",
    "    dI_dt = beta*S*I/N0 - gamma*I\n",
    "    dR_dt = gamma*I\n",
    "\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "def fit_odeint(x, beta, gamma):\n",
    "    ''' To call integrate funtion of scipy'''\n",
    "    return integrate.odeint(SIR_model_fit, (S0, I0, R0), t, args=(beta, gamma))[:,1]  #we are only fetching dI\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('SIR Modelling Started.')\n",
    "    warnings.filterwarnings('ignore')\n",
    "    df_analyse = pd.read_csv('../data/processed/COVID_full_flat_table.csv', sep=';')\n",
    "    df_analyse.sort_values('date', ascending=True)\n",
    "    df_analyse = df_analyse.drop(['date'],axis=1)\n",
    "    df_SIR_model = pd.DataFrame()\n",
    "    start_count = 0\n",
    "\n",
    "    for each_country in df_analyse:\n",
    "        #if each_country == 'Germany':\n",
    "        #print(each_country)\n",
    "        ydata = np.array(df_analyse[each_country][35:])\n",
    "        t, ydata, fitted = Handle_SIR_Modelling(ydata)\n",
    "        df_SIR_model[each_country] = fitted\n",
    "    df_SIR_model.to_csv('../data/processed/COVID_SIR_Model_Data.csv',sep=';', index = False)\n",
    "    print('Number of rows stored - : ' + str(df_SIR_model.shape[0]))\n",
    "    print('SIR Modelling Ended.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Visual Board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c:\\Users\\saisr\\Dropbox\\Lecture Materials\\EDS\\eds_covid\\notebooks\nDash is running on http://127.0.0.1:8050/\n\n * Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: on\n    country        date  confirmed  confirmed_filtered  confirmed_DR  \\\n235   India  2020-09-13  4846427.0           4848422.8     50.992411   \n\n     confirmed_filtered_DR  deaths  \n235              49.871634    67.0  \n    country        date  confirmed  confirmed_filtered  confirmed_DR  \\\n234   India  2020-09-12  4754356.0           4753115.8      48.54506   \n\n     confirmed_filtered_DR  deaths  \n234              48.883904   316.0  \n"
    }
   ],
   "source": [
    "# %load ../src/visualization/visualize.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import dash\n",
    "dash.__version__\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output,State\n",
    "import dash_daq as daq\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import os\n",
    "print(os.getcwd())\n",
    "df_input_large=pd.read_csv('../data/processed/COVID_final_set.csv',sep=';')\n",
    "df_input_recov=pd.read_csv('../data/processed/COVID_final_recov_set.csv',sep=';')\n",
    "df_input_daily=pd.read_csv('../data/processed/COVID_final_daily_set.csv',sep=';')\n",
    "df_analyse = pd.read_csv('../data/processed/COVID_full_flat_table.csv',sep=';')\n",
    "df_SIR_data = pd.read_csv('../data/processed/COVID_SIR_Model_Data.csv',sep=';')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = dash.Dash(external_stylesheets=[dbc.themes.LUX, 'https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css'])\n",
    "app.layout = html.Div([\n",
    "\n",
    "    dcc.Markdown('''\n",
    "    #  Applied Data Science on COVID-19 data\n",
    "\n",
    "    Goal of the project is to teach data science by applying a cross industry standard process,\n",
    "    it covers the full walkthrough of: automated data gathering, data transformations,\n",
    "    filtering and machine learning to approximating the doubling time, and\n",
    "    (static) deployment of responsive dashboard.\n",
    "\n",
    "    ''',style={'text-align':'center','border-style': 'solid'}),\n",
    "\n",
    "\n",
    " \n",
    "    html.Br(),html.Br(),html.Br(),\n",
    "\n",
    "\n",
    "\n",
    "    dbc.Row([\n",
    "        ### input + panel\n",
    "        dbc.Col(md=5, children=[\n",
    "            dcc.Markdown('''\n",
    "            ## Select Country for Country level Stats\n",
    "            '''),\n",
    "\n",
    "\n",
    "            dcc.Dropdown(\n",
    "                id='country_drop_down_stats',\n",
    "                options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "                value='India', # which is pre-selected\n",
    "                multi=False\n",
    "            ),\n",
    "            html.Br(),html.Br(),\n",
    "            html.Div([\n",
    "                dcc.Tabs(id='tabs-example', value='tab-1', children=[\n",
    "                    dcc.Tab(   label='Cummulative', value='tab-1', children=[\n",
    "                        html.Div([\n",
    "                            html.Br(),html.Br(),\n",
    "                            dbc.Row([\n",
    "                                dbc.Col(md=3, children=[\n",
    "                                dcc.Markdown('''\n",
    "                                **Scale Modes:**\n",
    "                                ''',style={\"font-weight\": \"900\",\"font-size\": \"17px\"}),\n",
    "                                ]),\n",
    "                                dbc.Col(md=4, children=[\n",
    "                                    dcc.RadioItems(\n",
    "                                        options=[\n",
    "                                            {'label': 'Uniform', 'value': 'linear'},\n",
    "                                            {'label': 'Logarithmic', 'value': 'log'},\n",
    "                                            \n",
    "                                        ],\n",
    "                                        value='linear',\n",
    "                                        id='scale_type',\n",
    "                                        labelStyle={'display': 'inline-block'}\n",
    "                                    ),\n",
    "                                ])\n",
    "                            ])\n",
    "                        \n",
    "                        ]),\n",
    "                        dcc.Graph( id='multi_graph'),\n",
    "                        \n",
    "                    ]),\n",
    "                    dcc.Tab(   label='Daily', value='tab-2', children=[\n",
    "                        \n",
    "                        \n",
    "                        dcc.Graph( id='multi_graph_daily'),\n",
    "                        \n",
    "                    \n",
    "                    ]),\n",
    "                ]),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ]),\n",
    "            html.Br(),html.Br(),html.Br(),\n",
    "            #dcc.Graph( id='multi_graph'),\n",
    "\n",
    "        ]),\n",
    "        ### plots\n",
    "        dbc.Col(md=5, children=[\n",
    "            \n",
    "            html.Div(id=\"output-panel\", style={'marginLeft': 250, 'marginTop': 250}),\n",
    "            \n",
    "        ])\n",
    "    ]),\n",
    "\n",
    "\n",
    "    html.Br(),html.Br(),html.Br(),\n",
    "    html.Div([\n",
    "        dcc.Markdown('''\n",
    "        ## Multi-Select Country for Doubling Rate Visualisation\n",
    "        ''',style={'text-align':'center'}),\n",
    "\n",
    "        html.Br(),html.Br(),\n",
    "        dcc.Dropdown(\n",
    "            id='country_drop_down',\n",
    "            options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "            value=['US', 'Germany','India'], # which are pre-selected\n",
    "            multi=True,\n",
    "            style=dict(\n",
    "                        width='60%',\n",
    "                        verticalAlign=\"middle\"\n",
    "                    )\n",
    "        ),\n",
    "\n",
    "        # dcc.Markdown('''\n",
    "        #     ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        #     '''),\n",
    "        \n",
    "        html.Br(),\n",
    "\n",
    "        dcc.Dropdown(\n",
    "            id='doubling_time',\n",
    "            options=[\n",
    "                \n",
    "                {'label': 'Timeline Doubling Rate', 'value': 'confirmed_DR'},\n",
    "                {'label': 'Timeline Doubling Rate Filtered', 'value': 'confirmed_filtered_DR'},\n",
    "            ],\n",
    "            value='confirmed_DR',\n",
    "            multi=False,\n",
    "            style=dict(\n",
    "                        width='60%',\n",
    "                        verticalAlign=\"middle\"\n",
    "                    )\n",
    "        ),\n",
    "        html.Br(),html.Br(),\n",
    "        html.Div([\n",
    "            dcc.Graph( id='main_window_slope'),\n",
    "        ], style=dict(position=\"relative\", width='60%',\n",
    "                    marginLeft= 250)),\n",
    "\n",
    "    html.Br(),html.Br(),html.Br(),\n",
    "    html.Div([\n",
    "        dcc.Markdown('''\n",
    "        ## Multi-Select Country for SIR Visualisation\n",
    "        ''',style={'text-align':'center'}),\n",
    "\n",
    "        html.Br(),html.Br(),\n",
    "        dcc.Dropdown(\n",
    "            id='country_drop_down_sir',\n",
    "            options=[ {'label': each,'value':each} for each in df_input_large['country'].unique()],\n",
    "            value=['US','India'], # which are pre-selected\n",
    "            multi=True,\n",
    "            style=dict(\n",
    "                        width='60%',\n",
    "                        verticalAlign=\"middle\"\n",
    "                    )\n",
    "        ),\n",
    "\n",
    "        # dcc.Markdown('''\n",
    "        #     ## Select Timeline of confirmed COVID-19 cases or the approximated doubling time\n",
    "        #     '''),\n",
    "        \n",
    "        \n",
    "        html.Br(),html.Br(),\n",
    "        html.Div([\n",
    "            dcc.Graph( id='sir_chart'),\n",
    "        ], style=dict(position=\"relative\", width='60%',\n",
    "                    marginLeft= 250)),\n",
    "\n",
    "    ],style={'border-style': 'solid', 'marginRight': 50, 'padding': '10px'})\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    ], style={'marginLeft': 50, 'marginTop': 25})\n",
    "])\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('multi_graph', 'figure'),\n",
    "    [Input('country_drop_down_stats', 'value'),\n",
    "    Input('scale_type', 'value')]\n",
    ")\n",
    "def update_cummulative_stacked_plot(country,scale_type):\n",
    "    \n",
    "\n",
    "\n",
    "    traces = []\n",
    " \n",
    "    df_plot=df_input_large[df_input_large['country'] == country]\n",
    "\n",
    "        \n",
    "    df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date','deaths']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "    df_plot_recov = df_input_recov[df_input_recov['country'] == country]\n",
    "    df_plot_recov=df_plot_recov[['state','country','recovered','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "\n",
    "    fig=make_subplots(rows=4, cols=1,\n",
    "                subplot_titles=(\"Total Confirmed\", \"Total Active \", \"Total Recovered\", 'Total Deaths'),\n",
    "                shared_xaxes=False, \n",
    "                vertical_spacing=0.1,\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['confirmed'],\n",
    "                        mode='markers+lines',\n",
    "                        opacity=0.9,\n",
    "                        fill='tozeroy',\n",
    "                 ), row=1,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['confirmed']- (df_plot_recov['recovered']+df_plot['deaths']),\n",
    "                        mode='markers+lines',\n",
    "                        opacity=0.9,\n",
    "                        fill='tozeroy',\n",
    "                 ), row=2,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df_plot_recov.date,\n",
    "                        y=df_plot_recov['recovered'],\n",
    "                        mode='markers+lines',\n",
    "                        opacity=0.9,\n",
    "                        fill='tozeroy',\n",
    "                        \n",
    "                 ), row=3,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['deaths'],\n",
    "                        mode='markers+lines',\n",
    "                        opacity=0.9,\n",
    "                        fill='tozeroy',\n",
    "                 ), row=4,col=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig.update_xaxes(type=\"date\",\n",
    "                    tickangle=-45,\n",
    "                    nticks=20,\n",
    "                    tickfont=dict(size=14,color=\"#7f7f7f\"), \n",
    "                    row=1, col=1)\n",
    "    fig.update_xaxes(type=\"date\",\n",
    "                    tickangle=-45,\n",
    "                    nticks=20,\n",
    "                    tickfont=dict(size=14,color=\"#7f7f7f\"), \n",
    "                    row=2, col=1)\n",
    "    fig.update_xaxes(type=\"date\",\n",
    "                    tickangle=-45,\n",
    "                    nticks=20,\n",
    "                    tickfont=dict(size=14,color=\"#7f7f7f\"), \n",
    "                    row=3, col=1)\n",
    "    fig.update_xaxes(type=\"date\",\n",
    "                    tickangle=-45,\n",
    "                    nticks=20,\n",
    "                    tickfont=dict(size=14,color=\"#7f7f7f\"), \n",
    "                    row=4, col=1)\n",
    "\n",
    "    fig.update_yaxes(type=scale_type, row=1, col=1, title='Confirmed infected people')\n",
    "    fig.update_yaxes(type=scale_type, row=2, col=1, title='Active infected people')\n",
    "    fig.update_yaxes(type=scale_type, row=3, col=1, title='Recovered people')\n",
    "    fig.update_yaxes(type=scale_type, row=3, col=1, title='Deaths')\n",
    "\n",
    "    fig.update_layout(dict (\n",
    "\n",
    "                width=900,\n",
    "                height=1500,\n",
    "                template=\"plotly_dark\",\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('multi_graph_daily', 'figure'),\n",
    "    [Input('country_drop_down_stats', 'value'),\n",
    "    ]\n",
    ")\n",
    "def update_cummulative_stacked_plot(country):\n",
    "\n",
    "    scale_type = 'linear'\n",
    "    traces = []\n",
    " \n",
    "    df_plot=df_input_daily[df_input_daily['country'] == country]\n",
    "\n",
    "        \n",
    "    #df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date','deaths']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "    df_plot_recov = df_input_recov[df_input_recov['country'] == country]\n",
    "    #df_plot_recov=df_plot_recov[['state','country','recovered','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "\n",
    "\n",
    "    fig=make_subplots(rows=4, cols=1,\n",
    "                subplot_titles=(\"Daily Confirmed\", \"Daily Active \", \"Daily Recovered\", \"Daily Deaths\"),\n",
    "                shared_xaxes=False, \n",
    "                vertical_spacing=0.1,\n",
    "    )\n",
    "    fig.add_trace(go.Bar(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['daily_confirmed'],\n",
    "                       \n",
    "                        \n",
    "                       \n",
    "                 ), row=1,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Bar(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['daily_confirmed'] - (df_plot['daily_recovered']+df_plot['daily_deaths']),\n",
    "                       \n",
    "                        \n",
    "                        \n",
    "                 ), row=2,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Bar(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['daily_recovered'],\n",
    "                       \n",
    "                        \n",
    "                        \n",
    "                 ), row=3,col=1\n",
    "    )\n",
    "    fig.add_trace(go.Bar(\n",
    "                        x=df_plot.date,\n",
    "                        y=df_plot['daily_deaths'],\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                 ), row=4,col=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    fig.update_xaxes(type=\"date\", row=1, col=1)\n",
    "    fig.update_xaxes(type=\"date\", row=2, col=1)\n",
    "    fig.update_xaxes(type=\"date\", row=3, col=1)\n",
    "    fig.update_xaxes(type=\"date\", row=4, col=1)\n",
    "\n",
    "    fig.update_yaxes(type=scale_type, row=1, col=1, title='Confirmed infected people')\n",
    "    fig.update_yaxes(type=scale_type, row=2, col=1, title='Active infected people')\n",
    "    fig.update_yaxes(type=scale_type, row=3, col=1, title='Recovered people')\n",
    "    fig.update_yaxes(type=scale_type, row=3, col=1, title='Deaths')\n",
    "    \n",
    "    \n",
    "    fig.update_layout(dict (\n",
    "\n",
    "               width=900,\n",
    "                height=1500,\n",
    "                template=\"plotly_dark\",\n",
    "                \n",
    "\n",
    "        ))\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('main_window_slope', 'figure'),\n",
    "    [Input('country_drop_down', 'value'),\n",
    "    Input('doubling_time', 'value')]\n",
    "    )\n",
    "def update_figure(country_list, show_doubling):\n",
    "    \n",
    "    if 'doubling_rate' in show_doubling:\n",
    "        my_yaxis={'type':\"log\",\n",
    "               'title':'Approximated doubling rate over 3 days (larger numbers are better #stayathome)'\n",
    "              }\n",
    "    else:\n",
    "        my_yaxis={'type':\"log\",\n",
    "                  'title':'Confirmed infected people (source johns hopkins csse, log-scale)'\n",
    "              }\n",
    "\n",
    "\n",
    "    traces = []\n",
    "    fig1 = go.Figure()\n",
    "\n",
    "    for each in country_list:\n",
    "\n",
    "        df_plot=df_input_large[df_input_large['country']==each]\n",
    "\n",
    "        if show_doubling=='doubling_rate_filtered':\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.mean).reset_index()\n",
    "        else:\n",
    "            df_plot=df_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "       #print(show_doubling)\n",
    "\n",
    "\n",
    "        fig1.add_trace(go.Scatter(dict(x=df_plot.date,\n",
    "                                y=df_plot[show_doubling],\n",
    "                                mode='markers+lines',\n",
    "                                opacity=0.9,\n",
    "                                name=each,\n",
    "                                \n",
    "                        ))\n",
    "                )\n",
    "    \n",
    "\n",
    "    fig1.update_layout(dict (\n",
    "                width=1280,\n",
    "                height=720,\n",
    "                template=\"plotly_dark\",\n",
    "                xaxis={'title':'Timeline',\n",
    "                        'tickangle':-45,\n",
    "                        'nticks':20,\n",
    "                        'tickfont':dict(size=14,color=\"#7f7f7f\"),\n",
    "                      },\n",
    "\n",
    "                yaxis=my_yaxis,\n",
    "                \n",
    "                \n",
    "        ))\n",
    "    return fig1\n",
    "\n",
    "\n",
    "\n",
    "# Python function to render output panel\n",
    "@app.callback(output=Output(\"output-panel\",\"children\"), inputs=[Input('country_drop_down_stats', 'value'),])\n",
    "def render_output_panel(country):\n",
    "    df_card_plot = df_input_large[df_input_large['country'] == country]\n",
    "    df_card_plot_recov = df_input_recov[df_input_recov['country'] == country]\n",
    "\n",
    "    df_card_plot=df_card_plot[['state','country','confirmed','confirmed_filtered','confirmed_DR','confirmed_filtered_DR','date','deaths']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "    df_card_plot_recov=df_card_plot_recov[['state','country','recovered','date']].groupby(['country','date']).agg(np.sum).reset_index()\n",
    "    \n",
    "\n",
    "\n",
    "    total_cases_until_today, active_cases_today, total_deaths, total_recovered = int(df_card_plot[-1:].confirmed), int(df_card_plot[-1:].confirmed) - (int(df_card_plot_recov[-1:].recovered) + int(df_card_plot[-1:].deaths)), \\\n",
    "                                                                                    int(df_card_plot[-1:].deaths), int(df_card_plot_recov[-1:].recovered)\n",
    "    print(df_card_plot[-1:])\n",
    "    print(df_card_plot[-2:-1])\n",
    "    #increases over previous day\n",
    "    total_cases_increase, active_cases_increase, total_deaths_increase, total_recovered_increase = \\\n",
    "        int(df_card_plot[-1:].confirmed) - int(df_card_plot[-2:-1].confirmed), \\\n",
    "        (int(df_card_plot[-1:].confirmed) - (int(df_card_plot_recov[-1:].recovered) + int(df_card_plot[-1:].deaths)))    -    (int(df_card_plot[-2:-1].confirmed) - (int(df_card_plot_recov[-2:-1].recovered) + int(df_card_plot[-2:-1].deaths))), \\\n",
    "        int(df_card_plot[-1:].deaths) -int(df_card_plot[-2:-1].deaths), int(df_card_plot_recov[-1:].recovered) -int(df_card_plot_recov[-2:-1].recovered)\n",
    "    \n",
    "    peak_color = \"white\"\n",
    "    panel = html.Div([\n",
    "        html.H4(country),\n",
    "        dbc.Card(body=True, className=\"text-white bg-primary\", children=[\n",
    "            \n",
    "            html.H6(\"Total cases until today:\", style={\"color\":\"white\"}),\n",
    "            html.Div([\n",
    "            html.H3(\"{:,.0f}\".format(total_cases_until_today), style={\"color\":\"white\", \"float\":\"left\",\"width\":\"35%\"}),\n",
    "            html.H4('[+' + \"{:,.0f}\".format(total_cases_increase) + ']', style={\"color\":\"yellow\", \"float\":\"right\",\"width\":\"65%\"}),\n",
    "            ]),\n",
    "\n",
    "\n",
    "            \n",
    "            html.H6(\"Active cases today:\", style={\"color\":\"white\"}),\n",
    "            html.Div([\n",
    "            html.H3(\"{:,.0f}\".format(active_cases_today), style={\"color\":\"white\", \"float\":\"left\",\"width\":\"35%\"}),\n",
    "            html.H4('[+' + \"{:,.0f}\".format(active_cases_increase) + ']', style={\"color\":\"yellow\", \"float\":\"right\",\"width\":\"65%\"}),\n",
    "            ]),\n",
    "            \n",
    "            html.H6(\"Recovered cases until today:\", style={\"color\":\"white\"}),\n",
    "            html.Div([\n",
    "            html.H3(\"{:,.0f}\".format(total_recovered), style={\"color\":\"white\", \"float\":\"left\",\"width\":\"35%\"}),\n",
    "            html.H4('[+' + \"{:,.0f}\".format(total_recovered_increase) + ']', style={\"color\":\"yellow\", \"float\":\"right\",\"width\":\"65%\"}),\n",
    "            ]),\n",
    "\n",
    "            html.H6(\"Total deaths until today:\", style={\"color\":\"white\"}),\n",
    "            html.Div([\n",
    "            html.H3(\"{:,.0f}\".format(total_deaths), style={\"color\":\"red\", \"float\":\"left\",\"width\":\"35%\"}),\n",
    "            html.H4('[+' + \"{:,.0f}\".format(total_deaths_increase) + ']', style={\"color\":\"red\", \"float\":\"right\",\"width\":\"65%\"}),\n",
    "            ]),\n",
    "        \n",
    "        ])\n",
    "    ])\n",
    "    return panel\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('sir_chart', 'figure'),\n",
    "    [Input('country_drop_down_sir', 'value')])\n",
    "def update_figure(country_list):\n",
    "    traces = []\n",
    "    fig =go.Figure()\n",
    "    if(len(country_list) > 0):\n",
    "        for each in country_list:\n",
    "            country_data = df_analyse[each][35:]\n",
    "            ydata = np.array(country_data)\n",
    "            t = np.arange(len(ydata))\n",
    "            fitted = np.array(df_SIR_data[each])\n",
    "            #t, ydata, fitted = Handle_SIR_Modelling(ydata)\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x = t,\n",
    "                y = ydata,\n",
    "                mode = 'markers+lines',\n",
    "                name = each+str(' - Truth'),\n",
    "                opacity = 0.9\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x = t,\n",
    "                y = fitted,\n",
    "                mode = 'markers+lines',\n",
    "                name = each+str(' - Simulation'),\n",
    "                opacity = 0.9\n",
    "            ))\n",
    "\n",
    "    fig.update_layout(dict(\n",
    "            width = 1280,\n",
    "            height = 720,\n",
    "            title = 'Fit of SIR model for: '+', '.join(country_list),\n",
    "            xaxis = {\n",
    "                'title': 'Days', #'Fit of SIR model for '+str(each)+' cases',\n",
    "                'tickangle': -45,\n",
    "                'nticks' : 20,\n",
    "                'tickfont' : dict(size = 14, color = '#7F7F7F')\n",
    "            },\n",
    "            yaxis = {\n",
    "                'title': 'Population Infected',\n",
    "                'type': 'log'\n",
    "            },\n",
    "            template=\"plotly_dark\",\n",
    "        ))        \n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run_server(debug=True, use_reloader=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1600108135679"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}